{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9793046d-1783-4823-82b6-fa002e859111",
   "metadata": {},
   "source": [
    "# Monthly Story Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b85e03f6-22dc-4346-8815-77bfb5fa626b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Data: 100%|███████████████████████████████████████████████████████████████████| 35/35 [00:02<00:00, 16.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'medium_full_data.csv' saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "\n",
    "url = 'https://medium.com/_/graphql'\n",
    "headers = {\n",
    "    'cookie': 'nonce=L4H2WYxN; uid=75a03e334406; sid=1:WNtHAkbjaPYuHZv6y/nwjE5mUzXRj3KfmAH6n8EQdqWxVuEFRGAjsvHsW2TP8r5f; xsrf=10a06cd49ecb; _cfuvid=lkpzJLFquiVtYRo2ERyjlvw2YSwvbtMxEv8IvNq38bc-1742138913168-0.0.1.1-604800000; cf_clearance=69i4Ooh7.1J8_mKkQIriOqsQsnS24G9JIYPiPPAHOXg-1742139792-1.2.1.1-LeWAsHDq6xEiYniZ7YlHHPZvh1f1ndlnOys0Exju280z4K4JR0803FMHqGD4T7e8SD_6U1Oj20FbGUyQHVfKuWPpWtiEiQTzkQbsLnnQmv52yJoWCTzbCTM1_LDfsQ8BRzk_0Oc2K1.Ql0LoguzcKYuE52.rlai16K5nFw8dOJ3.SlMA_JhQFFUyOYaYHbA7u6uhCUrozM4XKKsRfUW7b3o9JHatvTaKcgCQbJ5_R8jM_iyTvAMJx91IUM4w.pfkdm_KpNk4CQA02xJa_3AK0xbVlnXcXiE65Tk8qGNeEQ7TMOa748u3Sh4Td7MpWjR7qHeB4xrD_a865smZpJE4jMGX8T6MuyT1S3CW22G1Iug; _dd_s=rum=0&expire=1742140931186',  # Replace with actual token\n",
    "}\n",
    "\n",
    "def get_created_at():\n",
    "    payload = [{\"operationName\":\"ViewerQuery\",\"variables\":{},\"query\":\"query ViewerQuery {\\n  viewer {\\n    __typename\\n    id\\n    allowEmailAddressSharingEditorWriter\\n    dismissableFlags\\n    emailObfuscated\\n    geolocation {\\n      country\\n      __typename\\n    }\\n    hasGroupGiftingEnabled\\n    hasPastMemberships\\n    hasSubdomain\\n    imageId\\n    isEligibleToImportEmails\\n    isEligibleToViewNewResponses\\n    isMembershipTrialEligible\\n    isSuspended\\n    membership {\\n      id\\n      tier\\n      memberSince\\n      friendSince\\n      __typename\\n    }\\n    name\\n    partnerProgramEnrollment {\\n      id\\n      status\\n      __typename\\n    }\\n    postSubscribeMembershipUpsellShownAt\\n    styleEditorOnboardingVersionSeen\\n    twitterScreenName\\n    unverifiedEmail\\n    username\\n    viewerEdge {\\n      id\\n      createdAt\\n      __typename\\n    }\\n  }\\n}\\n\"}]\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[0]['data']['viewer']['viewerEdge']['createdAt']\n",
    "    else:\n",
    "        print(\"Failed to fetch 'createdAt' data.\")\n",
    "        return None\n",
    "\n",
    "def generate_monthly_timestamps(created_at):\n",
    "    start_date = datetime.fromtimestamp(created_at / 1000)\n",
    "    current_date = datetime.now()\n",
    "    timestamps = []\n",
    "\n",
    "    while start_date <= current_date:\n",
    "        _, last_day = calendar.monthrange(start_date.year, start_date.month)\n",
    "        next_month = start_date.replace(day=1) + timedelta(days=last_day)\n",
    "        end_time = min(next_month, current_date)\n",
    "        timestamps.append((\n",
    "            int(start_date.timestamp() * 1000),\n",
    "            int(end_time.timestamp() * 1000)\n",
    "        ))\n",
    "        start_date = next_month\n",
    "\n",
    "    return timestamps\n",
    "\n",
    "# Step 3: Fetch data for each month\n",
    "def fetch_data(time_range):\n",
    "    start_time, end_time = time_range\n",
    "    payload = {\"operationName\":\"UserMonthlyStoryStatsTimeseriesQuery\",\"variables\":{\"username\":\"kalyan45\",\"input\":{\"startTime\":start_time,\"endTime\":end_time}},\"query\":\"query UserMonthlyStoryStatsTimeseriesQuery($username: ID!, $input: UserPostsAggregateStatsInput!) {\\n  user(username: $username) {\\n    id\\n    postsAggregateTimeseriesStats(input: $input) {\\n      __typename\\n      ... on AggregatePostTimeseriesStats {\\n        ...MonthlyStoryStats_aggregatePostTimeseriesStats\\n        __typename\\n      }\\n    }\\n    __typename\\n  }\\n}\\n\\nfragment MonthlyStoryStatsTotals_postStats on PostStats {\\n  viewers\\n  readers\\n  __typename\\n}\\n\\nfragment MonthlyStoryStatsChart_postStatsPoint on PostStatsPoint {\\n  timestamp\\n  stats {\\n    total {\\n      viewers\\n      readers\\n      __typename\\n    }\\n    __typename\\n  }\\n  __typename\\n}\\n\\nfragment MonthlyStoryStats_aggregatePostTimeseriesStats on AggregatePostTimeseriesStats {\\n  totalStats {\\n    ...MonthlyStoryStatsTotals_postStats\\n    __typename\\n  }\\n  points {\\n    ...MonthlyStoryStatsChart_postStatsPoint\\n    __typename\\n  }\\n  __typename\\n}\\n\"}\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Step 4: Parallel execution with ThreadPoolExecutor and tqdm\n",
    "def collect_data():\n",
    "    created_at = get_created_at()\n",
    "    if not created_at:\n",
    "        return\n",
    "\n",
    "    all_data = []\n",
    "    time_ranges = generate_monthly_timestamps(created_at)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {executor.submit(fetch_data, time_range): time_range for time_range in time_ranges}\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Fetching Data\"):\n",
    "            data = future.result()\n",
    "            if data:\n",
    "                points = data['data']['user']['postsAggregateTimeseriesStats']['points']\n",
    "                for point in points:\n",
    "                    timestamp = datetime.fromtimestamp(point['timestamp'] / 1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                    viewers = point['stats']['total']['viewers']\n",
    "                    readers = point['stats']['total']['readers']\n",
    "                    all_data.append({'timestamp': timestamp, 'viewers': viewers, 'readers': readers})\n",
    "\n",
    "    # Convert to DataFrame and save\n",
    "    df = pd.DataFrame(all_data)\n",
    "    df.to_csv('medium_full_data.csv', index=False)\n",
    "    print(\"CSV file 'medium_full_data.csv' saved successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    collect_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f3e92b-f19b-45f4-ab61-f9a19b35d06a",
   "metadata": {},
   "source": [
    "# Audience Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8446d506-b2cb-46c3-bc7d-c12299e201f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "url = 'https://medium.com/@kalyan45/audience/stats/export?source=--------------------------------------------'\n",
    "\n",
    "# Headers to mimic a browser request\n",
    "headers = {\n",
    "    'cookie': 'nonce=L4H2WYxN; uid=75a03e334406; sid=1:WNtHAkbjaPYuHZv6y/nwjE5mUzXRj3KfmAH6n8EQdqWxVuEFRGAjsvHsW2TP8r5f; xsrf=10a06cd49ecb; _cfuvid=lkpzJLFquiVtYRo2ERyjlvw2YSwvbtMxEv8IvNq38bc-1742138913168-0.0.1.1-604800000; cf_clearance=69i4Ooh7.1J8_mKkQIriOqsQsnS24G9JIYPiPPAHOXg-1742139792-1.2.1.1-LeWAsHDq6xEiYniZ7YlHHPZvh1f1ndlnOys0Exju280z4K4JR0803FMHqGD4T7e8SD_6U1Oj20FbGUyQHVfKuWPpWtiEiQTzkQbsLnnQmv52yJoWCTzbCTM1_LDfsQ8BRzk_0Oc2K1.Ql0LoguzcKYuE52.rlai16K5nFw8dOJ3.SlMA_JhQFFUyOYaYHbA7u6uhCUrozM4XKKsRfUW7b3o9JHatvTaKcgCQbJ5_R8jM_iyTvAMJx91IUM4w.pfkdm_KpNk4CQA02xJa_3AK0xbVlnXcXiE65Tk8qGNeEQ7TMOa748u3Sh4Td7MpWjR7qHeB4xrD_a865smZpJE4jMGX8T6MuyT1S3CW22G1Iug; _dd_s=rum=0&expire=1742140931186',  # Replace with actual token\n",
    "}\n",
    "\n",
    "# Send the request\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    csv_data = StringIO(response.content.decode('utf-8'))\n",
    "    df = pd.read_csv(csv_data)\n",
    "    df.to_csv(\"Audience Stats.csv\", index=False)\n",
    "else:\n",
    "    print(\"Failed to fetch data:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964f797e-4396-48cf-bcab-7a171c745269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
